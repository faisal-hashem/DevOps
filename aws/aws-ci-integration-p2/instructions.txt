Continuous Integration Process:
Code should be build and test everytime there is a commit. This is CI. If there is a manual build in place, this will not be possible.

Server Approach: Manual overhead and time consuming.
Cloud Services: Set up AWS CI Pipeline. Short MTTR (Mean Time To Repair), AGILE, No OPs, No Human Intervention

AWS Tools:
- Code Commmit (Version Control System)
- Code Artifact (Maven Repo for Dependencies)
- Code Build (Build Sservice from AWS)
- Code Deploy (Artifact Deloyment Service)

- SonarCloud  (Sonarqube Cloud Services)
- Checkstyle (Code Analysis from Build Job)
- Code Pipeline (Service to Integrate all jobs together)

Architecture AWS Pipeline:
Source --> Review --> Build

Source: (AWS Code Commit) --> Review: (AWS CodeBuild - Pull Dependencies from AWS CodeArtifact) <-> SonarCloud --> Build (AWS CodeBuild - Pulls Dependencies from AWS CodeArtifact) --> AWS S3 Bucket (Artifact Storage)

Step 1: Code Commit Setup: CC Repository, IAM User w/Policies, SSH Auth from local machine, Copy code to CC Repo, Test pushing to CC repo.

- Create CodeCommit Repo:
    - Create Maven repository - vprofile-code-repo

- IAM User with custom policies for CC - one to one access to CC
    - Create IAM User, Policy for CC, Give Rights for this Policy to use Specific Repo, Attach Policy to User:
        - In IAM, create user- vprofile-code-admin - Add policy and create new custom policy. Give all CodeCommit rights. 
        - Within the CodeCommit policy screen, you will need to select the CodeCommit repository to point to by ARN. 
        - Select Specify ARN, and select This Account, your region (us-east-2), repo name you created earlier.
        - Give policy name: vprofile-repo-fullaccess
        - Go back to previous tab, search for the newly created policy and click add. user is created now. 
    - Create Access Key, login to AWS CLI w/ Access ID/Key:
        - Create access key for this user under Security Credentials. Save the CSV file with all the info. 
        - Make sure to have aws cli, run aws --Version
        - run aws configure and add your access id and access key here

- SSH auth to CodeCommit Repo from our local machine:
    - Create a SSH key on your local machine. ssh-keygen and use the name vpro-codecommit_rsa
    - Upload public key to the IAM AWS User we just created. 
    - Create a config file on local machine for the private key to recognize the public key during authentication
    - in .ssh directory add a file called config with the following:
        Host git-codecommit.*.amazonaws.com
        User Enter-Your-Access-Key-Here (this is your SSH key ID from AWS)
        IdentityFile ~/.ssh/vpro-codecommit_rsa  #point to public key
    - Now the private key will be used during SSH, you can test by: ssh -v git-codecommit.us-east-2.amazonaws.com 
    - Make sure the connection is successful. If not, re-create the ssh key pair and re-upload and make sure there is no extra spaces.


- Migrate vProfile repo from Github to codecommit. Clone to our PC and then upload to CodeCommit repo
    - Do a git clone https://github.com/hkhcoder/vprofile-project.git
    - cd into this
    - run cat .git/config .. In the url remote origin, we will need to replace that to your aws code commit
    - Before doing this, lets first go through all the branches we want to migrate to aws:
        - git branch -a
        - git checkout aws-ci 
        - git checkout aws-cd 
        - git checkout ci-jenkins
        - git checkout docker
        - etc.

    - You can also use a for loop against the entire list of git branches -a and checkout them all by running the following:
        - git branch -a | grep remotes | grep -v HEAD | cut -d / -f3 > ./br
        - To view each value in the for loop run this: for i in `cat ./br` ; do echo $i ; done
        - To checkout each run this: for i in `cat ./br` ; do git checkout $i ; done
        - We have checked out all the branches

    - Remove the git origin under .git on local machine
        - git remote rm origin
        - cat .git/config (should now be all clear)

    - Now we will add AWS code commit in here (Click clone URL on the AWS Code Commit):
        - git remote add origin ssh://git-codecommit.us-east-2.amazonaws.com/v1/repos/vprofile-code-repo
        - git push origin --all (This will push all the checkout branches to aws code commit, can view it there now.)
        

Step 2: Code Artifact Setup: Create Artifact Repository, Configure Sonar Cloud to connectivity, Parameter Store setup
    - Create AWS Code Artifact Repository
        - Connect the AWS Code Artifact to Maven store
        - Create Domain Name for this Account - mandohashdevops
        - After created, you should see 2 repos under the artifact. We will point to the maven central store repo.
    
    - Create Builspec file for Sonar:
        - Under Maven Repository, Click on View connection instructructions. We will PULL, mvn, Review Step 3-6. We will need to open VS code and go to vprofile-project.
        - Browse to the ci-aws branch and under aws-files, open sonar_buildspec.yml. We will run these commands through the buildspec file.
        - Before running, lets review the pom.xml file and the settings.xml file.  
            - So the buildspec file will export the AWS variable for token. And the settings.xml file will grab it.
            - The repo details are mentioned in the pom.xml file and authentication info is in the settings.xml (token)
        - The build spec file is to create the sonar cloud setup. All the details will be saved in the codebuild.
    
    - Retrieve Access Token from Sonar Cloud
        - Login to sonarcloud.io using github. 
        - Click my account, security, generate token. 
        - Create new organization. Give a unique name and free plan. 
        - CLick Analyze project manually
        - display name: vprofile-repo
        - Project key - mandohashdevops_vprofile-repo, public profile. 
        - New code for project, we will use previous version. Click create.
        - Go to the project, repo, expand side bar and click Information. Grab the organization key. mandohashdevops
    
    - Create Parameter Store for the Sonar Build Spec files variables:
        - Go to the buildspec file. The env variables, parameter-store can be stored in a secret store. 
        - Go to AWS Systems Manager
        - Click on Parameter store on the side bar. 
        - Lets start grabbing all the parameters from the buildspec file and store the details in the AWS parameter store:
            - Organization: use organization key from sonar cloud
            - HOST: https://sonarcloud.io
            - Project: use project key from sonar cloud
            - LOGIN: secure string - the token from sonar cloud
    
Step 3: Create a CodeBuild project for Sonar - good for 1 or 2 projects, not that frequent codebuild is good. But complexity Jenkins is good.
    - Update buildspec file with own Maven Artifact info:
        - Modify Pom.xml file <artifact> (bottom of the file) location to your maven repository store URL (can find this under connection instructions Step 5) 
        - Go to Settings. xml, replace all the <url> with the same URL. 
        - Move the sonar_buildspec.yml to the root directory (under vprofile_) of the project and rename to buildspec.yml
        - In AWS, grab the token (entire command) from Step 3 in the setup instructions (export CODEARTIFACT_AUTH_TOKEN=...) and replace it with old export line in the buildspec.yml file
        - Since this project is based off Java 11 which is deprecated. We will have to replace mvn sonar job line on the buildspec file with the following:
            - mvn sonar:sonar -Dsonar.login=$LOGIN -Dsonar.host.url=$HOST -Dsonar.projectKey=$Project -Dsonar.organization=$Organization -Dsonar.java.binaries=target/test-classes/com/visualpathit/account/controllerTest/ -Dsonar.junit.reportsPath=target/surefire-reports/ -Dsonar.jacoco.reportsPath=target/jacoco.exec -Dsonar.java.checkstyle.reportPaths=target/checkstyle-result.xml -Dsonar.scanner.force-deprecated-java-version=true
        - Commit the changes from the AWS repo in your VS Code and push it to the AWS repo and Verify.

    - Create and Run Code Build project for Sonar Analysis:
        - Go to Build tab, click Get Started, Create Project. Name it vpro-code-analysis. 
            - Source code is CodeCommit, select repo and ci-aws branch. 
            - Environment should be Ubuntu, Standard RunTime, 5.0 Image. 
        - Role: AWS will create a role name for you, but remember this role wont have access to the parameter store.
            - Need to go to this role after, codebuild51-vpro-code-analysis-service-role, and assign permissions. 
        - BuildSpec file: By Default buildspec file is searched on the root directory, thats why we moved it there. BUT we can change it. 
        - Cloudwatch Logs: these are essential, create a group name: vprofile-ohio-codebuild, stream name: sonarCodeAnalysis
        - Click Create, but build will fail since it cannot access the parameter store. 
        - Go to the build project you just created, click Edit on the Environment and copy the Service Role.
        - Go to IAM and search for the service role and click on the Policies side tab and click Create Policy. 
            - Select the service, search for Systems Manager, 
                - LIST select DescribeParameters. (List 1 parameter)
                - READ select DescribeDocumentParameters, GetParameter, GetParameters, GetParameterHistory, GetParametersByPath, (Read, 5 parameters)
                - After policy is created, go back to the Service Role and add permissions for the new policy you just created. 
            - Add another policy to access the CodeArtifact. AWSCodeArtifactReadOnlyAccess. 
        - Run the Build job by clicking Start Build, check build logs for any errors.
        - Once the build is successful, you should be able to see all the results in sonar cloud for the code. 
        - This job is designed to pass due to the Quality Gate exceptions we have placed.

Step 4: Modify Buildspec file and Create build job for the main Build job
    - We will use the other buildspec file - /aws-files/build-buildspec.yml
    - Get the export command from the maven store instructructions or grab it from the sonar build spec file (export CODEARTIFACT_AUTH_TOKEN=...) and paste it in the file
    - Make sure env for parameter store is commented out. We will not be using parameter store for this build.
    - Commit the changes to AWS 
    - We will point the Build Project directly to this location /aws-file/build-buildspec.yml
    - This time during the AWS CodeBuild project creation, we will do everything the same as before except for:
        - Buildspec file location, point to aws-files\build_buildspec.yml
        - No Artifact selection, since the pipeline will push it to the s3 bucket.
        - Group name is same as before. Stream name will different.BuildArtifact
    - Assign the role role, AWSCodeArtifactReadOnlyAccess policy permission. 
    - Start the build and check for any errors

Step 5: Build S3 Bucket with Key, SNS messaging and AWS Pipeline
    - Create S3 Bucket, create a key "pipeline-artifacts".
    - Create SNS Topic, with emails going to a email address 
    - Go to AWS Pipeline, create the pipeline, source provider will be Code Commit, select your Repo and branch. All is default. 
        - The Pipeline will contain the Source Code from Repo, Build job from Sonar, Build job for main Build and output to s3 bucket
          Source Code > Sonar Analysis Build > Build Job > Export to s3 
        - Build provider is AWS CodeBuild, select region, select build artifact project name. 
        - We wont select Deploy provider for now, Save it and STOP the execution from happening for now.
        - Edit the pipeline, and After the SOURCE step add a Sonar code analysis step
            - Action Provider=AWSCodeBuild, same region, input artifact= SourceArtifact. Project name: vpro-code-analysis. 
        - Add Deploy to s3 step after Build. 
            - Action Provider=Amazon S3, same region, Input Artifact= BuildArtifact. Select the bucket, copy the folder name as the deployment path. Select Extract file before deploy. 
    - Now modify the pipeline settings, click Notifications, add your email address there for notifications. 
    - Run the Pipeline
    - Once its successful, test run a commit from VS code to make sure pipeline kicks off. 
