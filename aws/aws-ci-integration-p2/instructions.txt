Continuous Integration Process:
Code should be build and test everytime there is a commit. This is CI. If there is a manual build in place, this will not be possible.

Server Approach: Manual overhead and time consuming.
Cloud Services: Set up AWS CI Pipeline. Short MTTR (Mean Time To Repair), AGILE, No OPs, No Human Intervention

AWS Tools:
- Code Commmit (Version Control System)
- Code Artifact (Maven Repo for Dependencies)
- Code Build (Build Sservice from AWS)
- Code Deploy (Artifact Deloyment Service)

- SonarCloud  (Sonarqube Cloud Services)
- Checkstyle (Code Analysis from Build Job)
- Code Pipeline (Service to Integrate all jobs together)

Architecture AWS Pipeline:
Source --> Review --> Build

Source: (AWS Code Commit) --> Review: (AWS CodeBuild - Pull Dependencies from AWS CodeArtifact) <-> SonarCloud --> Build (AWS CodeBuild - Pulls Dependencies from AWS CodeArtifact) --> AWS S3 Bucket (Artifact Storage)

Step 1: Code Commit Setup: CC Repository, IAM User w/Policies, SSH Auth from local machine, Copy code to CC Repo, Test pushing to CC repo.

- Create CodeCommit Repo:
    - Create Maven repository - vprofile-code-repo

- IAM User with custom policies for CC - one to one access to CC
    - Create IAM User, Policy for CC, Give Rights for this Policy to use Specific Repo, Attach Policy to User:
        - In IAM, create user- vprofile-code-admin - Add policy and create new custom policy. Give all CodeCommit rights. 
        - Within the CodeCommit policy screen, you will need to select the CodeCommit repository to point to by ARN. 
        - Select Specify ARN, and select This Account, your region (us-east-2), repo name you created earlier.
        - Give policy name: vprofile-repo-fullaccess
        - Go back to previous tab, search for the newly created policy and click add. user is created now. 
    - Create Access Key, login to AWS CLI w/ Access ID/Key:
        - Create access key for this user under Security Credentials. Save the CSV file with all the info. 
        - Make sure to have aws cli, run aws --Version
        - run aws configure and add your access id and access key here

- SSH auth to CodeCommit Repo from our local machine:
    - Create a SSH key on your local machine. ssh-keygen and use the name vpro-codecommit_rsa
    - Upload public key to the IAM AWS User we just created. 
    - Create a config file on local machine for the private key to recognize the public key during authentication
    - in .ssh directory add a file called config with the following:
        Host git-codecommit.*.amazonaws.com
        User Enter-Your-Access-Key-Here (this is your SSH key ID from AWS)
        IdentityFile ~/.ssh/vpro-codecommit_rsa  #point to public key
    - Now the private key will be used during SSH, you can test by: ssh -v git-codecommit.us-east-2.amazonaws.com 
    - Make sure the connection is successful. If not, re-create the ssh key pair and re-upload and make sure there is no extra spaces.


- Migrate vProfile repo from Github to codecommit. Clone to our PC and then upload to CodeCommit repo
    - Do a git clone https://github.com/hkhcoder/vprofile-project.git
    - cd into this
    - run cat .git/config .. In the url remote origin, we will need to replace that to your aws code commit
    - Before doing this, lets first go through all the branches we want to migrate to aws:
        - git branch -a
        - git checkout aws-ci 
        - git checkout aws-cd 
        - git checkout ci-jenkins
        - git checkout docker
        - etc.

    - You can also use a for loop against the entire list of git branches -a and checkout them all by running the following:
        - git branch -a | grep remotes | grep -v HEAD | cut -d / -f3 > ./br
        - To view each value in the for loop run this: for i in `cat ./br` ; do echo $i ; done
        - To checkout each run this: for i in `cat ./br` ; do git checkout $i ; done
        - We have checked out all the branches

    - Remove the git origin under .git on local machine
        - git remote rm origin
        - cat .git/config (should now be all clear)

    - Now we will add AWS code commit in here (Click clone URL on the AWS Code Commit):
        - git remote add origin ssh://git-codecommit.us-east-2.amazonaws.com/v1/repos/vprofile-code-repo
        - git push origin --all (This will push all the checkout branches to aws code commit, can view it there now.)
        

Step 2: Code Artifact Setup
    - Create AWS Code Artifact, we will connect this to the maven store to grab the dependencies for our code. We will need the dependencies for AWS CodeBuild REVIEW
    process. 
        - Connect the AWS Code Artifact to Maven store
        - Create Domain Name for this Account - mandohashdevops
        - After created, you shoukld see 2 repos under the artifact. We will point to the maven central store repo.
        - Click on View connection instructructions. We will PULL, mvn, Review Step 3-6. We will need to open VS code and go to vprofile-project.
        - Browse to the ci-aws branch and under aws-files, open sonar_buildspec.yml. We will run these commands through the buildspec file.
        - Before running, lets review the pom.xml file and the settings.xml file.  
            - So the buildspec file will export the AWS variable for token. And the settings.xml file will grab it.
            - The repo details are mentioned in the pom.xml file and authentication info is in the settings.xml (token)
        - The build spec file is to create the sonar cloud setup. All the details will be saved in the codebuild.
        - login to sonarcloud.io using github. 
        - Click my account, security, generate token. 
        - Create new organization. Give a unique name and free plan. 
        - CLick Analyze project manually
        - display name: vprofile-repo
        - Project key - mandohashdevops_vprofile-repo, public profile. 
        - New code for project, we will use previous version. Click create.
        - Go to the project, repo, expand side bar and click Information. Grab the organization key. mandohashdevops
        - Go to the buildspec file. The env variables, parameter-store can be stored in a secret store. 
            - Go to AWS Systems Manager
            - Click on Parameter store on the side bar. 
            - Lets start grabbing all the parameters from the buildspec file and store the details in the AWS parameter store:
                - Organization: use organization key from sonar cloud
                - HOST: https://sonarcloud.io
                - Project: use project key from sonar cloud
                - LOGIN: secure string - the token from sonar cloud
    
Step 3: Create a CodeBuild project for Sonar - good for 1 or 2 projects, not that frequent codebuild it good. But complexity Jenkins is good.
    - We will focus on changing the code artifact location (all the way in the bottom of the file) the pom.xml file to the AWS artifcat repo (in vprofile, under ci-aws branch)
    - Go to AWS Code Artifact maven-central-store, connect to repo and select mvn and grab the URL from step 5. 
    - Go to Settings. xml and replace all the URLs with this one: https://mandohashdevops-027040134225.d.codeartifact.us-east-2.amazonaws.com/maven/maven-central-store/
    - Now go to aws files folder and drag the sonar_buildspect.yml to the root directory under vprofile-project
    - Change the name of file to buildspec.yml 
    - Go back to the AWS connect to repo Code Artifact screen and grab the token (entire command) from Step 3.
        export CODEARTIFACT_AUTH_TOKEN=`aws codeartifact get-authorization-token --domain mandohashdevops --domain-owner 027040134225 --region us-east-2 --query authorizationToken --output text`
    - Paste it in the buildspec.yml file, replace the previous export command.
    - Commit the changes from the AWS repo in your VS Code and push it to the AWS repo
    - Verify all changes are there
    - Go to Build tab, click Get Started, Create Project. Name it vpro-code-analysis. 
    - Source code is CodeCommit, select repo and ci-aws branch. 
    - Environment should be Ubuntu, Standard RunTime, 5.0 Image. 
    - AWS will create a role name for you, but remember this role wont have access to the parameter store.
        - Need to go to this role after, codebuild51-vpro-code-analysis-service-role, and assign permissions. 
    - By Default buildspec file is searched on the root directory, thats why we moved it there. But we can change it. 
    - Cloudwatch Logs are essential, create a group name: vprofile-ohio-codebuild, stream name: sonarCodeAnalysis
    - Click Create, but build will fail since it cannot access the parameter store. 
    - Go to the build project you just created, click Edit on the Environment and copy the Service Role.
    - Go to IAM and search for the codebuil51... role and click on the Policies side tab and click Create Policy. 
        - Select the service, search for Systems Manager, under List select DescribeParameters. (List 1 parameter)
        - Under Read, select DescribeDocumentParameters, GetParameter, GetParameters, GetParameterHistory, GetParametersByPath, (Read, 5 parameters)
        - After policy is created, go back to the Role CodeBuild51.. and add permissions for the new policy you just created. 
        - You need to add another policy to access the CodeArtifact. AWSCodeArtifactReadOnlyAccess. 
    - Now lets run the Build job by clicking Start Build. Should take a long time and can check status under Phase Details.
    - This will take some time, if any errors, you can check under build logs.  
    - Since this project is based off Java 11 which is deprecated. We will have to replace mvn sonar job line on the buildspec file with the following:
    -    mvn sonar:sonar -Dsonar.login=$LOGIN -Dsonar.host.url=$HOST -Dsonar.projectKey=$Project -Dsonar.organization=$Organization -Dsonar.java.binaries=target/test-classes/com/visualpathit/account/controllerTest/ -Dsonar.junit.reportsPath=target/surefire-reports/ -Dsonar.jacoco.reportsPath=target/jacoco.exec -Dsonar.java.checkstyle.reportPaths=target/checkstyle-result.xml -Dsonar.scanner.force-deprecated-java-version=true
    - Once the build is successful, you should be able to see all the results in sonar cloud for the code. 
    - This job is designed to pass due to the Quality Gate exceptions we have placed.

Step 4: Build Artifact and Upload the artifact to S3 Bucket
    - We will use the other buildspec file. 
    - Similar to the last buildspec file. We will need to point this our AWS maven repo
    - Lets go and grab the export command from there from the maven store instructructions or grab it from the sonar build spec file:
        export CODEARTIFACT_AUTH_TOKEN=`aws codeartifact get-authorization-token --domain mandohashdevops --domain-owner 027040134225 --region us-east-2 --query authorizationToken --output text`
    - Everything else we can keep the same. We will use the path where the buildspec file is in
    - This time during the AWS CodeBuild project creation, we will do everything the same as before except for:
        - Buildspec file location, point to aws-files\build_buildspec.yml
        - No Artifact selection, since the pipeline will push it to the s3 bucket.
        - Group name is same as before. Stream name will different.BuildArtifact
    - Assign the role role, AWSCodeArtifactReadOnlyAccess policy permission. 
    - Start the build 

Step 5: Build S3 Bucket with Key, SNS messaging and AWS Pipeline
    - Create S3 Bucket, create a key "pipeline-artifacts".
    - Create SNS Topic, with emails going to a email address 
    - Go to AWS Pipeline, create the pipeline, source provider will be Code Commit, select your Repo and branch. All is default. 
    - Build provider is AWS CodeBuild, select region, select build artifact project name. 
    - We wont select Deploy provider for now.
    - Save it and stop the execution from happening for now.
    - Edit the pipeline, and after the source step add a sonar code analysis step
        - Action Provider=AWSCodeBuild, same region, input artifact= SourceArtifact. Project name: vpro-code-analysis. 
    - Add Deploy to s3 step after Build. 
        - Action Provider=Amazon S3, same region, Input Artifact= BuildArtifact. Select the bucket, copy the folder name as the deployment path. Select Extract file before deploy. 
    - Now modify the pipeline settings, click Notifications, add your email address there for notifications. 
    - Run the Pipeline
    - Once its successful, test run a commit from VS code to make sure pipeline kicks off. 
